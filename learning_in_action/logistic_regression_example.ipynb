{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 机器学习系列(1)_逻辑回归初步 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "作者：寒小阳 && 龙心尘\n",
    "时间：2015年10月。\n",
    "出处：http://blog.csdn.net/han_xiaoyang/article/details/49123419。\n",
    "声明：版权所有，转载请注明出处，谢谢。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1、总述\n",
    "\n",
    "逻辑回归是应用非常广泛的一个分类机器学习算法，它**将数据拟合到一个logit函数(或者叫做logistic函数)中**，从而能够完成**对事件发生的概率进行预测**。\n",
    "\n",
    ">说逻辑回归，我们得追溯到线性回归，想必大家对线性回归都有一定的了解，即对于多维空间中存在的样本点，我们用特征的线性组合去拟合空间中点的分布和轨迹。如下图所示：\n",
    "\n",
    "<img src=\"http://img.blog.csdn.net/20151014123301565?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center\" width=436 align=left />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "线性回归能对连续值结果进行预测，而现实生活中常见的另外一类问题是，分类问题。最简单的情况是是与否的二分类问题。比如说医生需要判断病人是否生病，银行要判断一个人的信用程度是否达到可以给他发信用卡的程度，邮件收件箱要自动对邮件分类为正常邮件和垃圾邮件等等。\n",
    "\n",
    ">既然能够用线性回归预测出连续值结果，那根据结果设定一个阈值是不是就可以解决这个问题了呢？事实是，对于很标准的情况，确实可以的，这里我们套用Andrew Ng老师的课件中的例子，下图中X为数据点肿瘤的大小，Y为观测结果是否是恶性肿瘤。通过构建线性回归模型，如hθ(x)所示，构建线性回归模型后，我们设定一个阈值0.5，预测hθ(x)≥0.5的这些点为恶性肿瘤，而hθ(x)<0.5为良性肿瘤。\n",
    "\n",
    "<img src='http://img.blog.csdn.net/20151014123518573?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center' width=456  />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "但很多实际的情况下，我们需要学习的分类数据并没有这么精准，比如说上述例子中突然有一个不按套路出牌的数据点出现，如下图所示：\n",
    "<img src='http://img.blog.csdn.net/20151014123606004?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center',width=456 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "你看，现在你再设定0.5，这个***判定阈值就失效了***，而现实生活的分类问题的数据，会比例子中这个更为复杂，而这个时候我们借助于***线性回归+阈值***的方式，已经很难完成一个***鲁棒性很好***的分类器了。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在这样的场景下，逻辑回归就诞生了。\n",
    ">它的核心思想是，如果***线性回归的结果输出***是一个***连续值***，而***值的范围是无法限定的***，那我们有没有办法把这个***结果值映射***为可以帮助我们判断的结果呢。\n",
    "\n",
    ">如果输出结果是 (0,1) 的一个***概率值***，这个问题就很清楚了。我们在数学上找了一圈，还真就找着这样一个简单的函数了，就是很神奇的***sigmoid函数***(如下)：\n",
    "<img src='http://img.blog.csdn.net/20151014123727818?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center'  width=123 />\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果把sigmoid函数图像画出来，是如下的样子：<img src='http://img.blog.csdn.net/20151014124034991?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center'  width=456 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "从函数图上可以看出，函数y=g(z)在z=0的时候取值为1/2，而随着z逐渐变小，函数值趋于0，z逐渐变大的同时函数值逐渐趋于1，而这正是一个概率的范围。\n",
    "所以我们定义线性回归的预测函数为Y=WTX，那么逻辑回归的输出Y= g(WTX)，其中y=g(z)函数正是上述sigmoid函数(或者简单叫做S形函数)。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  2、判定边界\n",
    "我们现在再来看看，为什么逻辑回归能够解决分类问题。这里引入一个概念，叫做***判定边界***，可以理解为是用以***对不同类别的数据分割的边界***，边界的两旁应该是不同类别的数据。\n",
    "\n",
    "从二维直角坐标系中，举几个例子，大概是如下这个样子：\n",
    "<img src='http://img.blog.csdn.net/20151014124124641?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center' width=456  />\n",
    "\n",
    "<img src='http://img.blog.csdn.net/20151014124156527?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center' width=456  />\n",
    "<img src='http://img.blog.csdn.net/20151014124241795?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center' width=456  />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上述三幅图中的红绿样本点为不同类别的样本，而我们划出的线，不管是直线、圆或者是曲线，都能比较好地将图中的两类样本分割开来。这就是我们的判定边界，下面我们来看看，逻辑回归是如何根据样本点获得这些判定边界的。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们依旧借用Andrew Ng教授的课程中部分例子来讲述这个问题。\n",
    "\n",
    ">回到sigmoid函数，我们发现：  \n",
    "当g(z)≥0.5时, z≥0;\n",
    "\n",
    ">对于hθ(x)=g(θTX)≥0.5, 则θTX≥0, 此时意味着预估y=1;\n",
    "\n",
    ">反之，当预测y = 0时，θTX<0;\n",
    "\n",
    "所以我们认为***θTX = 0 ***是一个决策边界\n",
    "当它大于0或小于0时，逻辑回归模型分别预测不同的分类结果。\n",
    "\n",
    "先看第一个例子hθ(x)=g(θ0+θ1X1+θ2X2)，其中θ0 ,θ1 ,θ2分别取-3, 1, 1。则当−3+X1+X2≥0时, y = 1; 则X1+X2=3是一个决策边界，图形表示如下，刚好把图上的两类点区分开来：\n",
    "<img src='http://img.blog.csdn.net/20151014124638710?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center' width=226 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "例1只是一个线性的决策边界，当hθ(x)更复杂的时候，我们可以得到非线性的决策边界，例如：\n",
    "<img src='http://img.blog.csdn.net/20151014124838937?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center' width=234 />\n",
    "这时当x12+x22≥1时，我们判定y=1，这时的决策边界是一个圆形，如下图所示：\n",
    "<img src='http://img.blog.csdn.net/20151014124912098?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center' width 234 />\n",
    ">所以我们发现，理论上说，只要我们的hθ(x)设计足够合理，准确的说是g(θTx)中θTx足够复杂，我们能在不同的情形下，拟合出不同的判定边界，从而把不同的样本点分隔开来。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.代价函数与梯度下降\n",
    "我们通过对判定边界的说明，知道会有***合适的参数θ***使得***θTx=0成为很好的分类判定边界***，那么问题就来了，我们如何***判定我们的参数θ是否合适***，有多合适呢？更进一步，我们有没有办法去***求得这样的合适参数θ***呢？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这就是我们要提到的***代价函数与梯度下降了***。\n",
    "\n",
    "### 代价函数Cost Function\n",
    "其实是一种***衡量我们在这组参数***下***预估的结果***和***实际结果差距***的函数，比如说线性回归的代价函数定义为:\n",
    "<img width=\"242\" height=\"71\" alt=\"\" src=\"http://img.blog.csdn.net/20151014125116151?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center\">\n",
    "当然我们可以和线性回归类比得到一个代价函数，实际就是上述公式中hθ(x)取为逻辑回归中的g(θTx)\n",
    ">但是这会引发代价函数为“非凸”函数的问题，简单一点说就是这个函数有很多个局部最低点，如下图所示：\n",
    "<img src=\"http://52opencourse.com/?qa=blob&amp;qa_blobid=607435295049781725\" alt=\"非凸函数-我爱公开课-52opencourse.com\">\n",
    "而我们希望我们的代价函数是一个如下图所示，碗状结构的凸函数，这样我们算法求解到局部最低点，就一定是全局最小值点。\n",
    "<img src=\"http://52opencourse.com/?qa=blob&amp;qa_blobid=847516551720124317\" alt=\"凸函数-我爱公开课-52opencouse.com\">\n",
    "因此，上述的Cost Function对于逻辑回归是不可行的，我们需要其他形式的Cost Function来保证逻辑回归的成本函数是凸函数。\n",
    "\n",
    "我们跳过大量的数学推导，直接出结论了，我们找到了一个适合逻辑回归的代价函数:\n",
    "<img width=\"420\" height=\"77\" alt=\"\" src=\"http://img.blog.csdn.net/20151014130511356?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center\">\n",
    "Andrew Ng老师解释了一下这个代价函数的合理性，我们首先看当y=1的情况：\n",
    "<img width=\"260\" height=\"250\" src=\"http://52opencourse.com/?qa=blob&amp;qa_blobid=7499905772199633281\" alt=\"对数似然损失函数解释1-我爱公开课-52opencouse.com\">\n",
    "如果我们的类别y = 1, 而判定的hθ(x)=1，则Cost = 0，此时预测的值和真实的值完全相等，代价本该为0；而如果判断hθ(x)→0，代价->∞，这很好地惩罚了最后的结果。\n",
    "\n",
    "而对于y=0的情况，如下图所示，也同样合理：\n",
    "<img width=\"260\" height=\"250\" src=\"http://52opencourse.com/?qa=blob&amp;qa_blobid=16991899942735763470\" alt=\"对数似然损失函数解释2-我爱公开课-52opencourse.com\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 梯度下降\n",
    "梯度下降算法是***调整参数θ***使得***代价函数J(θ)***取得最小值的最基本方法之一。从直观上理解，就是我们在碗状结构的凸函数上取一个***初始值***，然后挪动这个值***一步步靠近最低点的过程***，如下图所示：\n",
    "<img width=\"350\" height=\"350\" alt=\"\" src=\"http://img.blog.csdn.net/20151014125344499?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center\">\n",
    "\n",
    "\n",
    "先简化一下逻辑回归的代价函数：\n",
    "<img width=\"500\" height=\"100\" src=\"http://52opencourse.com/?qa=blob&amp;qa_blobid=4662816715826976375\" alt=\"逻辑回归代价函数简化公式-我爱公开课-52opencourse.com\">\n",
    "\n",
    "从数学上理解，我们为了找到最小值点，就应该朝着下降速度最快的方向(导函数/偏导方向)迈进，每次迈进一小步，再看看此时的下降最快方向是哪，再朝着这个方向迈进，直至最低点。\n",
    "\n",
    "#### 迭代公式表示出来的最小化J(θ)的梯度下降算法如下：\n",
    "<img width=\"414\" height=\"163\" src=\"http://52opencourse.com/?qa=blob&amp;qa_blobid=5185913255970284499\" alt=\"逻辑回归梯度下降算法-我爱公开课-52opencourse.com\">\n",
    "<img width=\"421\" height=\"147\" src=\"http://52opencourse.com/?qa=blob&amp;qa_blobid=14303327028035669672\" alt=\"梯度下降算法-我爱公开课-52opencourse.com\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4、代码与实现\n",
    "\n",
    "我们来一起看两个具体数据上做逻辑回归分类的例子，其中一份数据为线性判定边界，另一份为非线性。\n",
    "\n",
    "示例1。\n",
    "\n",
    "第一份数据为data1.txt，部分内容如下：\n",
    "<img width=\"200\" height=\"260\" alt=\"\" src=\"http://img.blog.csdn.net/20151014125459234?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEPCAYAAABRHfM8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYBiGYRgFYYJhGIZhFIQJhmEYhlEQ/x8BBeFSQ2i/YgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x3db7a70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "    %matplotlib inline\n",
    "    from numpy import loadtxt, where ,array\n",
    "    from pylab import scatter, show, legend, xlabel, ylabel  \n",
    "      \n",
    "    #load the dataset  \n",
    "    data = loadtxt('dataset/data1.txt', delimiter=',')  \n",
    "      \n",
    "    X = data[:, 0:2]  \n",
    "    y = data[:, 2]  \n",
    "      \n",
    "    pos = where(y == 1)  \n",
    "    neg = where(y == 0)  \n",
    "    scatter(X[pos, 0], X[pos, 1], marker='o', c='b')  \n",
    "    scatter(X[neg, 0], X[neg, 1], marker='x', c='r')  \n",
    "    xlabel('Feature1/Exam 1 score')  \n",
    "    ylabel('Feature2/Exam 2 score')  \n",
    "    legend(['Fail', 'Pass'])  \n",
    "    show()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面我们写好计算sigmoid函数、代价函数、和梯度下降的程序："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    def sigmoid(X):  \n",
    "        '''''Compute sigmoid function '''  \n",
    "        den =1.0+ e **(-1.0* X)  \n",
    "        gz =1.0/ den  \n",
    "        return gz  \n",
    "    def compute_cost(theta,X,y):  \n",
    "        '''''computes cost given predicted and actual values'''  \n",
    "        m = X.shape[0]#number of training examples  \n",
    "        theta = reshape(theta,(len(theta),1))  \n",
    "          \n",
    "        J =(1./m)*(-transpose(y).dot(log(sigmoid(X.dot(theta))))- transpose(1-y).dot(log(1-sigmoid(X.dot(theta)))))  \n",
    "          \n",
    "        grad = transpose((1./m)*transpose(sigmoid(X.dot(theta))- y).dot(X))  \n",
    "        #optimize.fmin expects a single value, so cannot return grad  \n",
    "        return J[0][0]#,grad  \n",
    "    def compute_grad(theta, X, y):  \n",
    "        '''''compute gradient'''  \n",
    "        theta.shape =(1,3)  \n",
    "        grad = zeros(3)  \n",
    "        h = sigmoid(X.dot(theta.T))  \n",
    "        delta = h - y  \n",
    "        l = grad.size  \n",
    "        for i in range(l):  \n",
    "            sumdelta = delta.T.dot(X[:, i])  \n",
    "            grad[i]=(1.0/ m)* sumdelta *-1  \n",
    "        theta.shape =(3,)  \n",
    "        return  grad  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unindent does not match any outer indentation level (<ipython-input-23-3c3f6a6947d5>, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-23-3c3f6a6947d5>\"\u001b[1;36m, line \u001b[1;32m3\u001b[0m\n\u001b[1;33m    m, n = X.shape\u001b[0m\n\u001b[1;37m                    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unindent does not match any outer indentation level\n"
     ]
    }
   ],
   "source": [
    "def predict(theta, X):  \n",
    "        '''''Predict label using learned logistic regression parameters'''  \n",
    "    m, n = X.shape  \n",
    "    p = zeros(shape=(m,1))  \n",
    "    h = sigmoid(X.dot(theta.T))  \n",
    "    for it in range(0, h.shape[0]):  \n",
    "        if h[it]>0.5:  \n",
    "            p[it,0]=1  \n",
    "        else:  \n",
    "            p[it,0]=0  \n",
    "    return p  \n",
    "    #Compute accuracy on our training set  \n",
    "p = predict(array(theta), it)  \n",
    "print'Train Accuracy: %f'%((y[where(p == y)].size / float(y.size))*100.0)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "示例2.\n",
    "\n",
    "第二份数据为data2.txt，部分内容如下：\n",
    "<img width=\"145\" height=\"340\" alt=\"\" src=\"http://img.blog.csdn.net/20151014125654926?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center\">\n",
    "把数据的分布画出来\n",
    "<img width=\"450\" height=\"315\" alt=\"\" src=\"http://img.blog.csdn.net/20151014125725759?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们发现在这个例子中，我们没有办法再用一条直线把两类样本点近似分开了，所以我们打算试试多项式的判定边界，那么我们先要对给定的两个feature做一个多项式特征的映射。比如说，我们做了如下的一个映射：\n",
    "<img width=\"270\" height=\"240\" alt=\"\" src=\"http://img.blog.csdn.net/20151014125802837?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-24-2c9596fb854e>, line 15)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-24-2c9596fb854e>\"\u001b[1;36m, line \u001b[1;32m15\u001b[0m\n\u001b[1;33m    mapped_fea = append(<span style=\"font-family: Arial, Helvetica, sans-serif;\">mapped_fea</span><span style=\"font-family: Arial, Helvetica, sans-serif;\">, r, axis=1)</span>\u001b[0m\n\u001b[1;37m                        ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def map_feature(x1, x2):  \n",
    "    ''''' \n",
    "    Maps the two input features to polonomial features. \n",
    "    Returns a new feature array with more features of \n",
    "    X1, X2, X1 ** 2, X2 ** 2, X1*X2, X1*X2 ** 2, etc... \n",
    "    '''  \n",
    "    x1.shape =(x1.size,1)  \n",
    "    x2.shape =(x2.size,1)  \n",
    "    degree =6  \n",
    "    mapped_fea = ones(shape=(x1[:,0].size,1))  \n",
    "    m, n = mapped_fea.shape  \n",
    "    for i in range(1, degree +1):  \n",
    "        for j in range(i +1):  \n",
    "            r =(x1 **(i - j))*(x2 ** j)  \n",
    "            mapped_fea = append(<span style=\"font-family: Arial, Helvetica, sans-serif;\">mapped_fea</span><span style=\"font-family: Arial, Helvetica, sans-serif;\">, r, axis=1)</span>  \n",
    "    return mapped_fea  \n",
    "mapped_fea = map_feature(X[:,0], X[:,1]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 总结\n",
    "\n",
    "总结一下逻辑回归。\n",
    "> * 它始于输出结果为有实际意义的连续值的线性回归，但是线性回归对于分类的问题没有办法准确而又具备鲁棒性地分割，因此我们设计出了逻辑回归这样一个算法，它的输出结果表征了某个样本属于某类别的概率。\n",
    "\n",
    "\n",
    "> * 逻辑回归的成功之处在于，将原本输出结果范围可以非常大的θTX 通过sigmoid函数映射到(0,1)，从而完成概率的估测。\n",
    "\n",
    "\n",
    "> * 而直观地在二维空间理解逻辑回归，是sigmoid函数的特性，使得判定的阈值能够映射为平面的一条判定边界，当然随着特征的复杂化，判定边界可能是多种多样的样貌，但是它能够较好地把两类样本点分隔开，解决分类问题。\n",
    "\n",
    "\n",
    "> * 求解逻辑回归参数的传统方法是梯度下降，构造为凸函数的代价函数后，每次沿着偏导方向(下降速度最快方向)迈进一小部分，直至N次迭代后到达最低点。\n",
    "\n",
    "\n",
    "7、补充\n",
    "\n",
    "      本文的2份数据可在http://pan.baidu.com/s/1pKxJl1p上下载到，分别为data1.txt和data2.txt，欢迎大家自己动手尝试。\n",
    "\n",
    "      关于逻辑回归的完整ipython notebook示例代码可以在我的github上(https://github.com/HanXiaoyang/ML_examples/tree/master/logistic_regression)下载到，欢迎指正。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
